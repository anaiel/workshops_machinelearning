{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from glob import glob                                # Parcourir dossier de dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2                                           # traitement des images du dataset\n",
    "from keras.datasets import mnist                     # Importe le dataset de mnist\n",
    "from keras.utils import to_categorical               # pour modifier les labels\n",
    "from keras.models import Sequential, load_model      # type de modele\n",
    "from keras.layers import Dense, Flatten              # Fully Connected Layers\n",
    "from keras.layers import Conv2D, MaxPooling2D        # Convolutional layers + Maxpooling layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy    # Loss function\n",
    "\n",
    "# from keras.callbacks import TensorBoard\n",
    "\n",
    "import h5py                                          # Pour pouvoir enregistrer son modele en .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of handwritten digits with MNIST\n",
    "\n",
    "MNIST est un exemple très souvent utilisé pour commencer avec les CNN, son dataset existe sur keras et peut être directement importé avec la fonction **load_data( )**\n",
    "\n",
    "Note :\n",
    "- Le dataset de MNIST a 60 000 exemples d'entrainement et 10 000 exemples de training\n",
    "- Le format de chaque image est de 28x28 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Les données sont déjà séparées en training set et testing set sur keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir à quoi ressemble votre dataset avec un print. A noter que votre x_train est une liste [ ] de 60 000 exemples et que votre x_test est une liste de 10 000 exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== x_train ===\n",
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "(60000, 28, 28)\n",
      "\n",
      "=== y_train ===\n",
      "[5 0 4 ... 5 6 8]\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print ('=== x_train ===')\n",
    "print (x_train)\n",
    "print ('\\n=== y_train ===')\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaque exemple se compose de 28 listes de 28 valeurs (car 28x28 pixels), il y a donc 28x28 = 784 valeurs, une par pixel\n",
    "- Chaque pixel a une valeur comprise entre 0 et 255, car un int = 8 octets donc 2^8 = 256 valeurs possibles, mais on commence à zéro donc 0-255\n",
    "- Les labels sont une valeur unique comprise entre 0 et 9 et correspondent au digit de l'image en question  \n",
    "  \n",
    "Vous pouvez verifier la shape de votre dataset (x_train, x_test, y_train et y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (60000, 28, 28)\n",
      "y_train: (60000,)\n",
      "x_test: (10000, 28, 28)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print ('x_train:', x_train.shape)\n",
    "print ('y_train:', y_train.shape)\n",
    "print ('x_test:', x_test.shape)\n",
    "print ('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : Prepare Data\n",
    "\n",
    "\n",
    "Ensuite, une fois les données importées, nous devons les préparer afin qu'elles puissent être données à notre modèle  \n",
    "Dans un premier temps, nous allons ajouter une dimension à la fin de nos x_train et x_test pour préciser le nombre de canaux que nous utiliserons grâce à la fonction **.reshape( )**\n",
    "\n",
    "- 1 pour Noir et Blanc\n",
    "- 3 pour RGB\n",
    "- L pour nuances de gris\n",
    "\n",
    "Pour cet exemple, nous nous contenterons d'une image en N&B, donc la valeur de notre dimension supplémentaire sera égale à 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ensuite normaliser notre dataset afin que les valeurs de nos pixels soient comprises entre 0 et 1 plutôt qu'entre 0 et 255. Cela facilitera les calculs pour la machine.\n",
    "\n",
    "Pour ce faire, il faudra d'abord \"recaster\" nos variables *x_train* et *x_test* en tant que float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recast\n",
    "\n",
    "x_train = x_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "\n",
    "# Normalize\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a bien modifié nos training et testing sets, il nous reste à modifier nos labels de façon à ce que la machine puisse mieux les comprendre.\n",
    "\n",
    "Pour l'instant, notre y_train est une liste de 60 000 valeurs entre 0 et 9, qui sont les labels des images correspondantes. \n",
    "\n",
    "*y_train[8] = label de la 9ème image de notre dataset, x_train[8]*\n",
    "\n",
    "Plutôt que d'avoir un label qui soit une valeur comprise entre 0 et 9, on va préférer avoir un label qui a la forme d'un one-hot vecteur. C'est à dire un vecteur composé de 10 valeurs (0 ou 1), avec un 1 a la position correspondante au label, et des 0 partout ailleurs.\n",
    "\n",
    "*Exemple : on veut transformer un* **y_train[8] = 1** en **y_train[8] = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]**\n",
    "\n",
    "On va utiliser une fonction de keras appelée **to_categorical(a, b)** qui prend en paramètre :\n",
    "- a = la liste qu'on cherche à changer\n",
    "- b = le nombre de sorties que nous avons\n",
    "\n",
    "Note : Cette fonction saura automatiquement où placer le 1 dans votre vecteur. Vous devez donc juste lui donner le nombre de catégories possibles que notre modèle pourra avoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Create Model\n",
    "\n",
    "Maintenant que nos données sont prêtes, nous allons pouvoir créer notre modèle. Keras a énormément de fonctions qui nous permettent d'éviter d'avoir à recoder nos fonctions de loss ou de backpropagation, pour l'objectif de cet exercice, nous allons donc les utiliser :)\n",
    "\n",
    "Nous allons commencer par définir une variable en tant que modèle en utilisant la méthode Sequential de keras. Utiliser cette méthode nous facilitera le travail pour ajouter nos couches et train notre modèle. Pour plus d'infos vous pouvez checker la doc\n",
    "\n",
    "https://keras.io/models/sequential/\n",
    "\n",
    "Nous allons ensuite pouvoir y ajouter les couches dont nous avons besoin. Rappelez vous l'ordre des couches (D'abord les couches de conv, puis les couches de Maxpool, puis les Fully Connected)\n",
    "\n",
    "Pour ajouter une couche, vous pouvez utiliser la fonction **.add( )**\n",
    "\n",
    "\n",
    "Pour chaque couche de convolution, vous devrez préciser :  \n",
    "*Attention ! Pour la première couche, n'oubliez pas qu'il faut préciser l'* **input_shape**\n",
    "- Le nombre de neurones\n",
    "- La taille de kernel si couche conv\n",
    "- La taille de Pool si couche MaxPool\n",
    "- La fonction d'activation (nous utiliserons **'relu'**)\n",
    "\n",
    "Pour chaque couche de MaxPooling, vous devrez préciser :\n",
    "- La taille de Pool si couche MaxPool\n",
    "\n",
    "Pour chaque couche de Fully Connected, vous devrez préciser :\n",
    "- Le nombre de neurones\n",
    "- La fonction d'activation (nous utiliserons **'relu'**)\n",
    "*Attention ! Pour la dernière couche de FC, n'oubliez pas qu'il faut préciser le* **nombre de sorties et non le nombre de neurones** *et que votre fonction d'activation est* **'softmax'** *et non* **'relu'**\n",
    "\n",
    "Voici la doc qui vous aidera à mieux comprendre Sequential https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "Vous pouvez utiliser la fonction **.summary( )** pour voir les détails de vos couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 329,962\n",
      "Trainable params: 329,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# My model is based on the VGG convnet:\n",
    "\n",
    "# Define model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Ajouter les couches de convolution\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "\n",
    "# Ajouter les couches de MaxPooling\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Alterner entre couche de convolution et maxpooling\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Applatir le dataset en un seul array\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Ajouter les couches Fully Connected\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Ajouter la dernière couche FC, mais avec cette fois le nombre de sorties au lieu du nombre de neurones et 'softmax' comme activation\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compilation du modèle avant l'entrainement\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Recap de votre modèle, avec l'output shape à chaque couche\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 : Train Model and save it\n",
    "\n",
    "Nous devons maintenant entrainer notre modèle afin de voir ses performances. Pour cela, vous pouvez utiliser la fonction **.fit( )** qui prend en paramètres :\n",
    "- x_train\n",
    "- y_train,\n",
    "- votre taille de batch (favorisez les puissances de 2)\n",
    "- votre nombre d'epochs\n",
    "- votre proportion de validation (par ex 0.2 pour 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      " - 84s - loss: 0.1240 - acc: 0.9621 - val_loss: 0.0663 - val_acc: 0.9814\n",
      "Epoch 2/10\n",
      " - 87s - loss: 0.0415 - acc: 0.9870 - val_loss: 0.0473 - val_acc: 0.9849\n",
      "Epoch 3/10\n",
      " - 87s - loss: 0.0291 - acc: 0.9906 - val_loss: 0.0358 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      " - 82s - loss: 0.0215 - acc: 0.9929 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "Epoch 5/10\n",
      " - 82s - loss: 0.0173 - acc: 0.9947 - val_loss: 0.0353 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      " - 87s - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0432 - val_acc: 0.9897\n",
      "Epoch 7/10\n",
      " - 83s - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0521 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      " - 81s - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0415 - val_acc: 0.9913\n",
      "Epoch 9/10\n",
      " - 86s - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0367 - val_acc: 0.9918\n",
      "Epoch 10/10\n",
      " - 94s - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0461 - val_acc: 0.9892\n",
      "10000/10000 [==============================] - 5s 473us/step\n",
      "score =  [0.03516661382293969, 0.9898]\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=2, validation_split=0.2)\n",
    "\n",
    "# On évalue ensuite notre modèle sur notre testing set\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('score = ', score)\n",
    "\n",
    "# Save le modèle\n",
    "model.save(\"votre_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir l'évolution de vos loss et accuracy grâce à cette fonction (Kdo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1661580b8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "historydf = pd.DataFrame(training.history, index=training.epoch)\n",
    "historydf.plot(ylim=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 : Testing our model\n",
    "\n",
    "Maintenant que nous avons un modèle, nous allons pouvoir le tester. Pour cela, nous allons créer nos propres images de digits en blanc sur noir en allant sur ce site : https://www.piskelapp.com/\n",
    "- Cliquer sur *Create Sprite* en haut à droite\n",
    "- Dans les paramètres, resize l'image à 28x28\n",
    "- N'oubliez pas de faire un **fond noir**\n",
    "- Dessinez le digit que vous voulez tester **en blanc** (n'hésitez pas à en faire plusieurs)\n",
    "- Exportez votre image (icone de la montagne)\n",
    "- Vérifiez que vous êtes bien sous l'onglet PNG, et cliquez sur *Download Selected frame export*\n",
    "\n",
    "Ensuite, une fois toutes vos images téléchargées, renommez les avec leur label correspondant (ce sera plus simple de vérifier le résultat), ex : image de 0 sera nommée 0.png\n",
    "  \n",
    "Mettez toutes vos images dans le même dossier que votre jupyter notebook\n",
    "  \n",
    "Pour aller chercher les images à tester, nous allons utiliser un module appelé **glob** qui se situe déjà dans vos imports.\n",
    "  \n",
    "Il faudra ensuite faire les mêmes modifications que nous avons faites à notre dataset dans le *STEP 2 : Prepare dataset* (reshape, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for  New Piskel-1.png.png is : 1 (expected  1 )\n",
      "The prediction for  New Piskel-2.png.png is : 2 (expected  2 )\n",
      "The prediction for  New Piskel-3.png.png is : 5 (expected  5 )\n",
      "The prediction for  New Piskel-4.png.png is : 9 (expected  0 )\n",
      "The prediction for  New Piskel-5.png.png is : 6 (expected  6 )\n",
      "The prediction for  New Piskel-6.png.png is : 7 (expected  7 )\n"
     ]
    }
   ],
   "source": [
    "# Recupérer toutes nos images\n",
    "all_images = glob('*.png')\n",
    "expected = [1, 2, 5, 0, 6, 7]\n",
    "i = 0;\n",
    "\n",
    "model = load_model('votre_model.h5')\n",
    "\n",
    "# Loop in all_images to process each image\n",
    "for image in all_images :\n",
    "    # Open the image using cv2\n",
    "    img = cv2.imread(image, 0)\n",
    "    \n",
    "    # Print the image to see (will only print the last one of the loop)\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    # Reshape the image, adding one dimension at the end\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Recast and normalize\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    # Get highest value index\n",
    "    prediction = np.argmax(prediction)\n",
    "    \n",
    "    print('The prediction for ', image, 'is :', prediction, '(expected ', expected[i], ')')\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
