{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes pour la classification du spam\n",
    "\n",
    "\n",
    "La classification naïve bayésienne (Naive bayes) est un algorithme de classification probabiliste relativement simple qui convient bien aux données que l'on peut catégoriser.\n",
    "\n",
    "En Machine Learning, les applications courantes de Naive Bayes sont la classification des courriels non sollicités (spam), l'analyse des sentiments (emotion analyses) et la catégorisation des documents (data categorisation). Naive Bayes présente des avantages par rapport aux autres algorithmes de classification couramment utilisés en raison de sa simplicité, de sa rapidité et de sa précision sur de petits ensembles de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Nous utiliserons les données du dépot d'apprentissage machine de l'UCI qui contient plusieurs commentaires Youtube de vidéos musicales très populaires. Chaque commentaire dans les données a été étiqueté comme spam ou ham (commentaire légitime), et nous utiliserons ces données pour former notre algorithme Naive Bayes pour la classification de spam commentaire youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "\n",
    "# Pour la manipulation des données\n",
    "import pandas as pd\n",
    "\n",
    "# Pour les opérations matricielles\n",
    "import numpy as np\n",
    "\n",
    "# Pour utiliser le regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-41f3a971fce1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-41f3a971fce1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    data_comments =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Charger les données du fichier 'YoutubeCommentsSpam.csv' en utilisant pandas\n",
    "data_comments = \n",
    "\n",
    "# Créer des libellés de colonne : \"content\" et \"label\". \n",
    "# conseils : la méthode 'colums' peut être utile \n",
    "\n",
    "\n",
    "# Afficher les premières lignes de notre ensemble de données pour s'assurer que la colonne \"label\" a été ajoutée\n",
    "data_comments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{ATTENTION: Ne regardez pas les liens dans les commentaires, ce sont des spams! ;)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les commentaires de spam dans les données\n",
    "# N'ALLEZ PAS SUR LES LIENS !!!!! sérieusement, ce sont des spams.... \n",
    "print(data_comments[\"content\"][data_comments[\"label\"] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En parcourant les commentaires qui ont été étiquetés comme spam dans ces données, il semble que ces commentaires sont soit sans rapport avec la vidéo, soit comme une forme de publicité. L'expression \"check out\" semble être très populaire dans ces commentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics and Data Cleaning\n",
    "\n",
    "Le tableau ci-dessous montre que cet ensemble de données se compose de $1959$ commentaires youtube, dont environ $49\\%$ sont des commentaires légitimes et environ $51\\%$ sont du spam. Cette grande variation de classes dans notre ensemble de données nous aidera à tester l'exactitude de nos algorithmes sur l'ensemble des données de test. \n",
    "\n",
    "La longueur moyenne de chaque commentaire est d'environ $96$ caractères, ce qui représente environ $15$ mots en moyenne par commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une nouvelle colonne pour la longueur de chaque commentaire\n",
    "# conseils: utiliser map et lambda\n",
    "data_comments['length'] = \n",
    "\n",
    "# Permet d'afficher un tableau avec plusieurs données statistiques (mean, stdev, min, max)\n",
    "data_comments[[\"label\",\"length\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour notre algorithme de classification Naive Bayes, nous diviserons les données en deux parties: entrainement et tests. La partie d'entrainement sera utilisé pour former l'algorithme de classification du spam, et l'ensemble de test ne sera utilisé que pour tester sa précision. \n",
    "\n",
    "En général, La partie d'entrainement devrait être plus grand que La partie de test et les deux devraient provenir de la même population (la population dans notre cas est Youtube commentaires pour les vidéos musicales). \n",
    "\n",
    "**Nous sélectionnerons au hasard $75\\%$ des données pour la formation et $25\\%$ des données pour les tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Séparons les données en 2 groupes ! (75% training, 25% test)\n",
    "\n",
    "# Ceci nous permet d'obtenir la même allocation aléatoire pour chaque série de codes. RTFM if you want ;)\n",
    "np.random.seed(2019)\n",
    "\n",
    "# Ajout d'un vecteur colonne 'uniform' de nombres générés aléatoirement entre 0 et 1 \n",
    "# Astuce : dans numpy, il existe une méthode pour prélever un échantillon à partir d'une distribution uniforme.\n",
    "data_comments[\"uniform\"] = \n",
    "\n",
    "# Comme le nombre dans notre colonne 'uniform' est distribué uniformément, \n",
    "# environ 75 % de ces chiffres devraient être inférieurs à 0,75 %, prenons ces 75 %.\n",
    "data_comments_train = \n",
    "\n",
    "# Même chose pour les 25 % de ces numéros qui sont supérieurs à 0,75\n",
    "data_comments_test = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifiez que les données d'entraînement contiennent à la fois des commentaires de spam et de ham\n",
    "data_comments_train[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Même chose pour le data test\n",
    "data_comments_test[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données d'entrainement et de test ont toutes deux un bon mélange de spam et de ham, nous sommes donc prêts à passer à la formation sur le classificateur Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-dd2d22f44c10>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-dd2d22f44c10>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    training_list_words =\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Joindre tout les commentaires dans une seule et même liste\n",
    "# Astuce: 'separator'.join(list)\n",
    "training_list_words = \n",
    "\n",
    "# Diviser la liste des commentaires en une liste de mots uniques\n",
    "# Astuce: set() and sorted()\n",
    "train_unique_words = \n",
    "\n",
    "# Nombre de mots uniques dans le data training\n",
    "vocab_size_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description résumée des commentaires\n",
    "print('Unique words in training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela devrait ressember à quelquechose comme ça:\n",
    "\n",
    "```Unique words in training data: 5898\n",
    "First 5 words in our unique set of words: \n",
    "['now!!!!!!', 'yellow', 'four', '/>.Pewdiepie', 'Does']```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actuellement, \"now !!\" et \"Now !!!!!!\", ainsi que \"DOES\", \"DoEs\", et \"does\" sont tous considérés comme des mots uniques. Pour la classification du spam, il est probablement préférable de traiter légèrement les données pour en améliorer l'exactitude. Dans notre cas, nous pouvons nous concentrer sur les lettres et les chiffres, ainsi que convertir tous les commentaires en minuscules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder uniquement les chiffres et les lettres\n",
    "# Astuce: utiliser regex et les list comprehension\n",
    "train_unique_words = \n",
    "\n",
    "# Convertir toutes les lettres en minuscule\n",
    "# Astuce: set() ?\n",
    "train_unique_words = \n",
    "\n",
    "# Nombre de mots uniques dans le data training\n",
    "vocab_size_train = \n",
    "\n",
    "# Description résumée des commentaires\n",
    "print('Unique words in processed training data: %s' % vocab_size_train)\n",
    "print('First 5 words in our processed unique set of words: \\n % s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes for Spam Classification\n",
    "\n",
    "Ok, alors voilà le plan :\n",
    "\n",
    "- Tout d'abord, nous avons séparer nos données de formation en 2 sous-ensembles : training et test.\n",
    "\n",
    "- puis nous allons créer plusieurs fonctions pour vérifier combien de fois chaque mot est apparu dans le spam et non dans les commentaires de spam, \n",
    "    - et vérifier la probabilité que chaque mot apparaisse dans le spam/non spam\n",
    "\n",
    "- alors les 2 fonctions les plus importantes : train() et classify()\n",
    "\n",
    "- Et enfin, nous allons vérifiez l'exactitude de nos prédictions.\n",
    "\n",
    "Passons au code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On initialise des dictionnaire avec des mots de commentaires comme \"keys\", et leur étiquette comme \"value\".\n",
    "trainPositive = dict()\n",
    "trainNegative = dict()\n",
    "\n",
    "# On initialise ces variables à zéro\n",
    "positiveTotal = \n",
    "negativeTotal = \n",
    "\n",
    "# Même chose, mais en float ;) \n",
    "pSpam = \n",
    "pNotSpam = \n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def initialize_dicts():\n",
    "\n",
    "# # On initialise les dictionnaires avec 0 comme valeur \n",
    "for word in train_unique_words:\n",
    "    # skip empty words('' and ' ')\n",
    "    if word ... or ...:\n",
    "        continue\n",
    "    \n",
    "    # Pour le moment, tout est classifier comme ham (légitime)\n",
    "    trainPositive[word] = 0\n",
    "    trainNegative[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-d350d815e653>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-d350d815e653>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    comment =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de fois que le mot dans le commentaire apparaît dans les commentaires de spam et ham\n",
    "def processComment(comment,label):\n",
    "    global positiveTotal\n",
    "    global negativeTotal\n",
    "    \n",
    "    # Séparer le commentaire en liste de mots\n",
    "    comment = \n",
    "    \n",
    "    # Pour chaque mot du commentaire\n",
    "    for ...\n",
    "        \n",
    "        #Checker si le mot est bien dans la base de donnée\n",
    "        \n",
    "        #Checker si ce n'est pas un '' ou ' '\n",
    "        \n",
    "        \n",
    "        # Checker si le mot n'est pas du spam (ham)\n",
    "        \n",
    "            \n",
    "            # Incrémenter le nombre de fois que le mot apparaît dans les commentaires non spam\n",
    "            \n",
    "            \n",
    "        # spam comments\n",
    "        \n",
    "            \n",
    "            # Incrémenter le nombre de fois que le mot apparaît dans les commentaires spam\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##METTRE LA FORMULE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, on a la fonction qui va calculer la Prob(word|spam) et Prob(word|ham)\n",
    "def conditionalWord(word,label):\n",
    "   \n",
    "    # Paramètre de lissage de Laplace (Laplace Smoothing)\n",
    "    # Rappel : pour avoir accès à une variable globale à l'intérieur d'une fonction \n",
    "    # vous devez le spécifier en utilisant le mot 'global'.\n",
    "    \n",
    "    \n",
    "    # word in ham comment\n",
    "    if(label == 0):\n",
    "        # Calculer Prob(word|ham)\n",
    "        \n",
    "    \n",
    "    # word in spam comment\n",
    "    else:\n",
    "        \n",
    "        # Calculer Prob(word|ham)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, on a la fonction qui va calculer la Prob(spam|comment) or Prob(ham|comment)\n",
    "def conditionalComment(comment,label):\n",
    "    \n",
    "    # On initialise la probabilité conditionelle\n",
    "    prob_label_comment = 1.0\n",
    "    \n",
    "    # On sépare le commentaire en liste de mots\n",
    "    \n",
    "    \n",
    "    # Pour chaque mot du commentaire\n",
    "    for ...\n",
    "        \n",
    "        # Calculer la valeur de P(label|comment)\n",
    "        # On suppose ici qu'on a une independance conditionnelle (p(A) * p(B))\n",
    "        \n",
    "    \n",
    "    return prob_label_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer plusieurs probabilités conditionnelles dans les données d'entraînement\n",
    "def train():\n",
    "    # Rappel: on aura besoin de pSpam et pNotSpam ici ;) \n",
    "\n",
    "\n",
    "    # Initialisation de nos variables: le nombre total de commentaires et le nombre de commentaires de spam \n",
    "    total = 0.0\n",
    "    num_spam = 0.0\n",
    "    \n",
    "    print('Starting training ...')\n",
    "    # Passez en revue chaque commentaire dans les données d'entraînement \n",
    "    for ...\n",
    "        \n",
    "       # Vérifiez si le commentaire est du spam ou non (ham)\n",
    "    \n",
    "       # Incrémenter les valeurs selon que le commentaire est du spam ou non\n",
    "        \n",
    "       # Mettre à jour le dictionnaire du spam et ham\n",
    "    \n",
    "    \n",
    "    # Calcule des probabilitées a priori, P(spam), P(ham)\n",
    "    pSpam = \n",
    "    pNotSpam = \n",
    "    print('Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer notre fonction train de Naive Bayes\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier les commentaires sont du spam ou ham\n",
    "def classify(comment):\n",
    "    \n",
    "    # get global variables\n",
    "    \n",
    "    \n",
    "    # Calculer la valeur proportionnelle à Pr(comment|ham)\n",
    "    isNegative = \n",
    "    \n",
    "    # Calculer la valeur proportionnelle à Pr(comment|spam)\n",
    "    isPositive = \n",
    "    \n",
    "    # Output -> True = spam, False = ham en fonction des 2 variables calculées précédemment (il faut comparer les variables)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser la prédiction du spam dans les données de test\n",
    "prediction_test = []\n",
    "\n",
    "# Obtenez la précision des prédictions sur les données d'essai\n",
    "for ...\n",
    "\n",
    "    # ajouter un commentaire classifié à la liste prediction_test \n",
    "    \n",
    "\n",
    "# Checker la précision: \n",
    "# D'abord le nombre de prédictions correctes \n",
    "correct_labels = \n",
    "# Ensuite la moyenne des prédictions correctes\n",
    "test_accuracy = \n",
    "\n",
    "#print prediction_test\n",
    "print(\"Proportion of comments classified correctly on test set: %s\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'écrire quelques commentaires pour voir s'ils sont classés comme spam ou ham. \n",
    "\n",
    "Rappelez-vous que le \"True\" est pour les commentaires de spam, et \"False\" est pour les commentaires ham. \n",
    "Essayez vous même !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam\n",
    "classify(\"Guys check out my new chanell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam\n",
    "classify(\"I have solved P vs. NP, check my video https://www.youtube.com/watch?v=dQw4w9WgXcQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ham\n",
    "classify(\"I liked the video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ham\n",
    "classify(\"Its great that this video has so many views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin...\n",
    "## Extending Bag of Words by Using TF-IDF\n",
    "\n",
    "Jusqu'à présent, nous avons utilisé le modèle du Bag of Words pour représenter les commentaires en tant que vecteurs. Le \"Bag of Words\" est une liste de tous les mots uniques trouvés dans les données training, alors chaque commentaire peut être représenté par un vecteur qui contient la fréquence de chaque mot unique qui apparaît dans le commentaire.\n",
    "\n",
    "Par exemple, si les données training contiennent les mots $(hi, how, how, my, grade, are, you),$ alors le texte \"how are you you\" peut être représenté par $(0,1,0,0,0,1,2).$ La principale raison pour laquelle nous faisons cela dans notre application est que les commentaires peuvent varier en longueur, mais la longueur des mots uniques reste fixe.\n",
    "\n",
    "Dans notre contexte, le TF-IDF est une mesure de l'importance d'un mot dans un commentaire par rapport à tous les mots de nos données de formation. Par exemple, si un mot tel que \"the\" apparaissait dans la plupart des commentaires, le TF-IDF serait petit car ce mot ne nous aide pas à faire la différence entre les commentaires spam et ham. Notez que \"TF\" signifie \"Term Frequency\" et \"IDF\" signifie \"Inverse Document Frequency\".\n",
    "\n",
    "En particulier, \"TF\" indiqué par $tf(w,c)$ est le nombre de fois que le mot $w$ apparaît dans le commentaire donné $c$. Alors que \"IDF\" est une mesure de la quantité d'informations qu'un mot donné fournit pour différencier les commentaires. PLus précisement, $IDF$ est formulé comme ceci:\n",
    "\n",
    "\n",
    ">$idf(w, D) = log(\\frac{\\text{Number of comments in train data $D$}}{\\text{Number of comments containing the word $w$}}).$ \n",
    "\n",
    "\n",
    "Pour combiner \"TF\" et \"IDF\" ensemble, nous prenons simplement le produit, donc:\n",
    "\n",
    "\n",
    ">$$TFIDF = tf(w,c) \\times idf(w, D) = (\\text{Number of times $w$ appears in comment $c$})\\times log(\\frac{\\text{Number of comments in train data $D$}}{\\text{Number of comments containing the word $w$}}).$$\n",
    "\n",
    "\n",
    "Maintenant, le $TF-IDF$ peut être utilisé pour pondérer les vecteurs qui résultent de l'approche \"Bag of Words\".\n",
    "\n",
    "Par exemple, supposons qu'un commentaire contienne \"ceci\" 2 fois, donc $tf = 2$. \n",
    "Si nous avions alors 1000 commentaires dans nos données de formation, et que le mot \"ceci\" apparaît dans 100 commentaires, $idf = log(1000/100) = 2.$. \n",
    "\n",
    "Par conséquent, dans cet exemple, le poids TF-IDF serait de $2*2 = 4$ pour le mot \"ceci\" apparaît deux fois dans un commentaire particulier. Pour incorporer TF-IDF dans le réglage des baies naïves, nous pouvons calculer :\n",
    "\n",
    ">$$Pr(word|spam) = \\frac{\\sum_{\\text{c is spam}}TFIDF(word,c,D)}{\\sum_{\\text{word in spam c}}\\sum_{\\text{c is spam}}TFIDF(word,c,D)+ \\text{Number of unique words in data}},$$ \n",
    "\n",
    ">where $TFIDF(word,c,D) = TF(word,c) \\times IDF(word,data).$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer TFIDF(word, comment, data)\n",
    "def TFIDF(comment, train):\n",
    "    \n",
    "    # Diviser le commentaire en une liste de mot\n",
    "    comment = \n",
    "    \n",
    "    # Initiailiser tf-idf selon la longueur du commentaire\n",
    "    tfidf_comment = \n",
    "    \n",
    "    # Initiailiser nombre de commentaires contenant un mot\n",
    "    num_comment_word = 0\n",
    "    \n",
    "    # Initialiser l'index pour les mots dans le commentaire\n",
    "    word_index = 0\n",
    "    \n",
    "    # Pour chaque mot du commentaire\n",
    "    for...\n",
    "        \n",
    "        # Calculer la fréquence des termes (tf)\n",
    "        # Compter la fréquence du mot dans les commentaires\n",
    "        tf = \n",
    "        \n",
    "        # Trouver le nombre de commentaires contenant un mot\n",
    "        for ...\n",
    "            \n",
    "            # Incrémenter le compteur de mots si le mot trouvé dans le commentaire\n",
    "            if ...\n",
    "        \n",
    "        # Calculer la fréquence du document inverse (idf)\n",
    "        # log(Nombre total de commentaires/nombre de commentaires avec mot)\n",
    "        idf = \n",
    "        \n",
    "        # Mettre a jour le poids tf-idf du mot\n",
    "        \n",
    "        \n",
    "        # Réinitialiser le nombre de commentaires contenant un mot\n",
    "        \n",
    "        \n",
    "        # Passer au mot suivant dans le commentaire\n",
    "        \n",
    "        \n",
    "    return tfidf_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF(\"Check out my new music video plz\",data_comments_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Et maintenant, implémente TFIDF avec ta fonction de classification\n",
    "# Have fun :D\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
